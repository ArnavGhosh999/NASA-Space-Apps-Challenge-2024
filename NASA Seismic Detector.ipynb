{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9534017,"sourceType":"datasetVersion","datasetId":5779538},{"sourceId":9555776,"sourceType":"datasetVersion","datasetId":5729851},{"sourceId":127087,"sourceType":"modelInstanceVersion","modelInstanceId":107004,"modelId":131340}],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom os import listdir\nfrom os.path import isfile, join\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout\nfrom tensorflow.keras.models import load_model\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2024-10-04T18:22:04.073994Z","iopub.execute_input":"2024-10-04T18:22:04.074394Z","iopub.status.idle":"2024-10-04T18:22:19.03004Z","shell.execute_reply.started":"2024-10-04T18:22:04.074354Z","shell.execute_reply":"2024-10-04T18:22:19.029159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mypath = \"/kaggle/input/seismic-data/data/train/moon\"\ncsv_files = [join(mypath, f) for f in listdir(mypath) if isfile(join(mypath, f))]","metadata":{"execution":{"iopub.status.busy":"2024-10-04T18:22:19.031916Z","iopub.execute_input":"2024-10-04T18:22:19.032658Z","iopub.status.idle":"2024-10-04T18:22:19.071876Z","shell.execute_reply.started":"2024-10-04T18:22:19.032593Z","shell.execute_reply":"2024-10-04T18:22:19.070967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"catalog_df = pd.read_csv(\"/kaggle/input/seismic-detection-across-the-solar-system/data/lunar/training/catalogs/apollo12_catalog_GradeA_final.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-10-04T18:22:19.073014Z","iopub.execute_input":"2024-10-04T18:22:19.073294Z","iopub.status.idle":"2024-10-04T18:22:19.10024Z","shell.execute_reply.started":"2024-10-04T18:22:19.073264Z","shell.execute_reply":"2024-10-04T18:22:19.09935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time_steps = 500  # Set your preferred time window length","metadata":{"execution":{"iopub.status.busy":"2024-10-04T18:22:19.10211Z","iopub.execute_input":"2024-10-04T18:22:19.10242Z","iopub.status.idle":"2024-10-04T18:22:19.107143Z","shell.execute_reply.started":"2024-10-04T18:22:19.102387Z","shell.execute_reply":"2024-10-04T18:22:19.106016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv1D, MaxPooling1D, Dropout, Flatten, Dense, BatchNormalization\n\n# CNN-based model for time-series classification\nmodel = Sequential()\n\n# Add convolutional layers\nmodel.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(time_steps, 2)))  # 2 is the number of features\nmodel.add(BatchNormalization())  # Helps with convergence\nmodel.add(MaxPooling1D(pool_size=2))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling1D(pool_size=2))\nmodel.add(Dropout(0.2))\n\n# Flatten and add a dense layer\nmodel.add(Flatten())\nmodel.add(Dense(64, activation='relu'))  # Fully connected layer after convolutions\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1, activation='sigmoid')) # Output layer for binary classification\n\n# model = load_model(\"/kaggle/working/quake_detector_model(Velocity_only)-CNN.h5\")\n# Compile the model\nmodel.compile(optimizer='adam', \n              loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=0.1), \n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-10-04T14:13:55.648184Z","iopub.execute_input":"2024-10-04T14:13:55.648565Z","iopub.status.idle":"2024-10-04T14:13:56.622805Z","shell.execute_reply.started":"2024-10-04T14:13:55.648528Z","shell.execute_reply":"2024-10-04T14:13:56.621866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def proximity_list(length, certain_index):\n    proximity = [0] * length  # Initialize list with zeros\n    max_distance = max(certain_index, length - 1 - certain_index)  # Max distance from certain_index to the start/end\n    for i in range(length):\n        # Calculate distance from the certain index\n        distance = abs(i - certain_index)\n        # Normalize the value so it peaks at 1 at the certain index and decreases symmetrically\n        proximity[i] = 1 - (distance / max_distance) \n    return proximity","metadata":{"execution":{"iopub.status.busy":"2024-10-04T14:13:56.624385Z","iopub.execute_input":"2024-10-04T14:13:56.624683Z","iopub.status.idle":"2024-10-04T14:13:56.629678Z","shell.execute_reply.started":"2024-10-04T14:13:56.624651Z","shell.execute_reply":"2024-10-04T14:13:56.62876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_file_in_batch(csv_file, model, index):\n    # Load a single CSV file\n    df = pd.read_csv(csv_file)\n        \n    df['proximity'] = proximity_list(len(df.index), catalog_df['time_rel(sec)'].iloc[index])\n    \n    # Include the new features along with time_rel and velocity\n    X = df[['proximity','velocity']].values\n    y = df['mq'].values\n    \n    \n    # Reshape X for LSTM (samples, time_steps, features)\n    X_seq, y_seq = [], []\n    for i in range(len(X) - time_steps):\n        X_seq.append(X[i:i + time_steps])\n        y_seq.append(y[i + time_steps - 1])\n        \n        \n    # Convert to NumPy arrays for model training\n    X_seq, y_seq = np.array(X_seq), np.array(y_seq)\n    \n    \n    # Train the model incrementally or append the processed data for batch processing\n    model.fit(X_seq, y_seq)\n    model.save('quake_detector_model(proximity)-CNN.h5')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-04T14:13:57.460573Z","iopub.execute_input":"2024-10-04T14:13:57.461182Z","iopub.status.idle":"2024-10-04T14:13:57.469248Z","shell.execute_reply.started":"2024-10-04T14:13:57.461143Z","shell.execute_reply":"2024-10-04T14:13:57.468233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Process files one by one\nc = 0\nfor csv_file in csv_files[0:1]:\n    print(c)\n    process_file_in_batch(csv_file, model, c)\n    c += 1 ","metadata":{"execution":{"iopub.status.busy":"2024-10-04T13:32:00.73645Z","iopub.execute_input":"2024-10-04T13:32:00.737161Z","iopub.status.idle":"2024-10-04T13:49:11.069311Z","shell.execute_reply.started":"2024-10-04T13:32:00.737122Z","shell.execute_reply":"2024-10-04T13:49:11.068508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom tensorflow.keras.models import load_model\n\n# Load the trained model\nmodel = load_model('/kaggle/input/scismic-model-cnn/tensorflow2/default/1/quake_detector_model(proximity)-CNN.h5')","metadata":{"execution":{"iopub.status.busy":"2024-10-04T18:22:19.108546Z","iopub.execute_input":"2024-10-04T18:22:19.108888Z","iopub.status.idle":"2024-10-04T18:22:20.155373Z","shell.execute_reply.started":"2024-10-04T18:22:19.108855Z","shell.execute_reply":"2024-10-04T18:22:20.154487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install obspy","metadata":{"execution":{"iopub.status.busy":"2024-10-04T18:25:35.861743Z","iopub.execute_input":"2024-10-04T18:25:35.862473Z","iopub.status.idle":"2024-10-04T18:25:54.975553Z","shell.execute_reply.started":"2024-10-04T18:25:35.862434Z","shell.execute_reply":"2024-10-04T18:25:54.974144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import obspy\n\n# Load the mseed file\nfile_path = '/kaggle/input/seismic-detection-across-the-solar-system/data/lunar/test/data/S12_GradeB/xa.s12.00.mhz.1970-02-18HR00_evid00016.mseed'\nstream = obspy.read(file_path)\n\n# Plot the data\nstream.plot()","metadata":{"execution":{"iopub.status.busy":"2024-10-04T18:50:48.496535Z","iopub.execute_input":"2024-10-04T18:50:48.497528Z","iopub.status.idle":"2024-10-04T18:50:48.979595Z","shell.execute_reply.started":"2024-10-04T18:50:48.497486Z","shell.execute_reply":"2024-10-04T18:50:48.978637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prepare your test data (assuming you have a test CSV file)\ntest_file = \"/kaggle/input/seismic-data/data/test/moon/12_b_00016.csv\"\ntest_df = pd.read_csv(test_file)\n\ntest_df['proximity'] = [0] * len(test_df.index)\n\n# Prepare the test data similar to how you prepared the training data\ntest_X = test_df[['proximity', 'velocity']].values\n\n# Reshape X for CNN (samples, time_steps, features)\ntime_steps = 500  # Adjust according to your model's time step requirement\nX_test = []\nfor i in range(len(test_X) - time_steps):\n    X_test.append(test_X[i:i + time_steps])\n\nX_test = np.array(X_test)\n\n# Make predictions\npredictions = model.predict(X_test)\n\n# Define thresholds for significant predictions\nhigh_threshold = 0.9\nlow_threshold = 0.1\n\n# Filter predictions greater than 0.9 and less than 0.1\nhigh_predictions = predictions[predictions.flatten() > high_threshold]\nhigh_indices = np.where(predictions.flatten() > high_threshold)[0]\n\nlow_predictions = predictions[predictions.flatten() < low_threshold]\nlow_indices = np.where(predictions.flatten() < low_threshold)[0]\n\n# Plot the results\nplt.figure(figsize=(15, 5))\n\n# Plot all predictions\nplt.plot(test_df['time_rel'][time_steps:], predictions, label='All Predictions', alpha=0.3)\n\n# Plot high predictions (> 0.9)\nplt.scatter(test_df['time_rel'][high_indices + time_steps], high_predictions, \n            color='green', label='High Predictions (> 0.9)', zorder=5)\n\n# Plot low predictions (< 0.1)\nplt.scatter(test_df['time_rel'][low_indices + time_steps], low_predictions, \n            color='blue', label='Low Predictions (< 0.1)', zorder=5)\n\n# Plot styling\nplt.xlabel('Time (seconds)')\nplt.ylabel('Prediction Probability')\nplt.title('Seismic Event Predictions (High > 0.9, Low < 0.1)')\nplt.legend()\nplt.grid(True)\n\n# Show plot\nplt.show()\n\n# Print out the times of significant high and low predictions\nhigh_times = test_df['time_rel'][high_indices + time_steps]\nlow_times = test_df['time_rel'][low_indices + time_steps]\n\nprint(\"Times of high predictions (probability > 0.9):\")\nprint(high_times)\n\nprint(\"\\nTimes of low predictions (probability < 0.1):\")\nprint(low_times)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T18:50:53.255307Z","iopub.execute_input":"2024-10-04T18:50:53.255706Z","iopub.status.idle":"2024-10-04T18:51:40.477095Z","shell.execute_reply.started":"2024-10-04T18:50:53.255668Z","shell.execute_reply":"2024-10-04T18:51:40.476099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}